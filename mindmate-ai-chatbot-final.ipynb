{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11438096,"sourceType":"datasetVersion","datasetId":7164779}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  MindMate:AI ‚Äì An Emotion-Aware Motivational Chatbot\nMindMate is a GenAI-powered chatbot designed to provide emotional support, motivation, and companionship. It detects the user's emotions from text or audio and responds with empathy, encouragement, and positivity.\n\nThis project uses:\n- Google Gemini 1.5 Flash for generating responses\n- Emotion detection with keyword mapping\n- gTTS (Text-to-Speech) for voice output\n- Widgets-based UI with support for personality mode selection and audio uploads\n\n> Built as part of the GenAI Capstone to showcase real-world impact using multi-modal interaction.\n","metadata":{}},{"cell_type":"code","source":"# Install necessary libraries\n# Core Gemini AI\n!pip install -q google-generativeai\n\n# Voice Input and Output\n!pip install -q gTTS SpeechRecognition\n\n# UI Elements for Notebooks\n!pip install -q ipywidgets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:26:48.344678Z","iopub.execute_input":"2025-04-16T16:26:48.344996Z","iopub.status.idle":"2025-04-16T16:27:02.120505Z","shell.execute_reply.started":"2025-04-16T16:26:48.344972Z","shell.execute_reply":"2025-04-16T16:27:02.119244Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Import required libraries\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\n\n# Fetch API key stored in Kaggle secrets\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\n# Configure Gemini AI with the fetched API key\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\n\n# Load Gemini API key securely\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:02.122211Z","iopub.execute_input":"2025-04-16T16:27:02.122505Z","iopub.status.idle":"2025-04-16T16:27:05.034242Z","shell.execute_reply.started":"2025-04-16T16:27:02.122478Z","shell.execute_reply":"2025-04-16T16:27:05.033249Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    model_name=\"models/gemini-1.5-flash-001\",\n    system_instruction=(\n        \"You are a kind, friendly, and supportive AI companion. \"\n        \"Your goal is to provide emotional support, mental wellness advice, and daily motivation. \"\n        \"Keep responses positive, warm, and encouraging. Be empathetic and never judgmental.\"\n    )\n)\n\n# Start chat instance\nchat = model.start_chat(history=[])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:05.035421Z","iopub.execute_input":"2025-04-16T16:27:05.035867Z","iopub.status.idle":"2025-04-16T16:27:05.041280Z","shell.execute_reply.started":"2025-04-16T16:27:05.035841Z","shell.execute_reply":"2025-04-16T16:27:05.040238Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def detect_emotion(text):\n    text = text.lower()\n    sad = [\"sad\", \"depressed\", \"tired\", \"hopeless\", \"lonely\", \"cry\"]\n    angry = [\"angry\", \"mad\", \"furious\", \"annoyed\"]\n    happy = [\"happy\", \"joy\", \"great\", \"awesome\", \"fantastic\"]\n    \n    if any(word in text for word in sad):\n        return \"sad\"\n    elif any(word in text for word in angry):\n        return \"angry\"\n    elif any(word in text for word in happy):\n        return \"happy\"\n    return \"neutral\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:05.043895Z","iopub.execute_input":"2025-04-16T16:27:05.044200Z","iopub.status.idle":"2025-04-16T16:27:05.068283Z","shell.execute_reply.started":"2025-04-16T16:27:05.044176Z","shell.execute_reply":"2025-04-16T16:27:05.067351Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from gtts import gTTS\nfrom IPython.display import Audio, display\nimport tempfile\n\ndef speak(text):\n    tts = gTTS(text)\n    with tempfile.NamedTemporaryFile(delete=True, suffix=\".mp3\") as fp:\n        tts.save(fp.name)\n        display(Audio(fp.name, autoplay=True))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:05.069215Z","iopub.execute_input":"2025-04-16T16:27:05.069493Z","iopub.status.idle":"2025-04-16T16:27:05.097368Z","shell.execute_reply.started":"2025-04-16T16:27:05.069461Z","shell.execute_reply":"2025-04-16T16:27:05.096415Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import speech_recognition as sr\n\ndef transcribe_audio(file_bytes):\n    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n        temp_audio.write(file_bytes)\n        temp_audio_path = temp_audio.name\n\n    recognizer = sr.Recognizer()\n    with sr.AudioFile(temp_audio_path) as source:\n        audio = recognizer.record(source)\n        try:\n            return recognizer.recognize_google(audio)\n        except sr.UnknownValueError:\n            return \"[Unclear audio]\"\n        except sr.RequestError:\n            return \"[API error]\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:05.098535Z","iopub.execute_input":"2025-04-16T16:27:05.099250Z","iopub.status.idle":"2025-04-16T16:27:05.133318Z","shell.execute_reply.started":"2025-04-16T16:27:05.099223Z","shell.execute_reply":"2025-04-16T16:27:05.132351Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# UI Elements\nchat_display = widgets.HTML(value=\"<b>MindMate is here for you!</b><br><br>\")\ninput_box = widgets.Text(placeholder=\"Type your message...\", description=\"You:\")\nsend_button = widgets.Button(description=\"Send üí¨\", button_style=\"success\")\nupload_audio = widgets.FileUpload(accept='.wav', multiple=False)\noutput = widgets.Output()\n\n# Visual message styling\ndef show_message(who, text, color):\n    return f\"<b style='color:{color}'>{who}:</b> {text}<br><br>\"\n\n# Handle sending text\ndef handle_send(_):\n    user_text = input_box.value.strip()\n    if user_text == \"\":\n        return\n\n    emotion = detect_emotion(user_text)\n    prompt = f\"[Emotion: {emotion}]\\nUser said: {user_text}\"\n\n    chat_display.value += show_message(\"You\", user_text, \"#0066cc\")\n    response = chat.send_message(prompt)\n    bot_reply = response.text\n    chat_display.value += show_message(\"MindMate\", bot_reply, \"#009933\")\n\n    speak(bot_reply)\n    input_box.value = \"\"\n\n# Handle audio input\ndef handle_audio_upload(change):\n    for name, file_info in upload_audio.value.items():\n        transcribed = transcribe_audio(file_info['content'])\n        input_box.value = transcribed\n        with output:\n            print(f\"Transcribed: {transcribed}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:05.134232Z","iopub.execute_input":"2025-04-16T16:27:05.134491Z","iopub.status.idle":"2025-04-16T16:27:05.154654Z","shell.execute_reply.started":"2025-04-16T16:27:05.134465Z","shell.execute_reply":"2025-04-16T16:27:05.153590Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"modes = {\n    \"Default\": \"You are a helpful and supportive chatbot.\",\n    \"Therapist\": \"You are a calm, empathetic therapist who offers emotional support.\",\n    \"Motivational Coach\": \"You are a high-energy coach who inspires action.\",\n    \"Friendly Buddy\": \"You are a cheerful, funny friend who makes people smile.\",\n    \"Wise Mentor\": \"You are a philosophical and wise mentor with deep advice.\"\n}\n\nmode_selector = widgets.Dropdown(\n    options=list(modes.keys()),\n    value=\"Default\",\n    description=\"Choose Mode:\",\n    style={'description_width': 'initial'},\n    layout=widgets.Layout(width='50%')\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:05.155695Z","iopub.execute_input":"2025-04-16T16:27:05.155933Z","iopub.status.idle":"2025-04-16T16:27:05.206057Z","shell.execute_reply.started":"2025-04-16T16:27:05.155915Z","shell.execute_reply":"2025-04-16T16:27:05.204923Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"send_button.on_click(handle_send)\nupload_audio.observe(handle_audio_upload, names='value')\n\ndisplay(chat_display)\ndisplay(widgets.HBox([input_box, send_button]))\ndisplay(widgets.Label(\"üé§ Upload Audio (WAV):\"))\ndisplay(upload_audio)\ndisplay(mode_selector)\ndisplay(output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T16:27:05.207307Z","iopub.execute_input":"2025-04-16T16:27:05.207646Z","iopub.status.idle":"2025-04-16T16:27:05.240113Z","shell.execute_reply.started":"2025-04-16T16:27:05.207618Z","shell.execute_reply":"2025-04-16T16:27:05.239195Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"HTML(value='<b>MindMate is here for you!</b><br><br>')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"041b0a8ccf8e42cfb30cb76010b82ca1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(Text(value='', description='You:', placeholder='Type your message...'), Button(button_style='su‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e2465e684294a808757c3d90b39baad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Label(value='üé§ Upload Audio (WAV):')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"554ca05831f3443fb843bb640450cba4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"FileUpload(value=(), accept='.wav', description='Upload')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a1f12c4c764c108a83f3e9a1eaebfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Dropdown(description='Choose Mode:', layout=Layout(width='50%'), options=('Default', 'Therapist', 'Motivationa‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0634ab8c188e4c3c8600c99805262909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3025920bd4b84030b7079470a67698a6"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}